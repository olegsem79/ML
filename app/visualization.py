# visualization.py
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report
import tensorflow as tf

def plot_training_history(history):
    """–í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –æ–±—É—á–µ–Ω–∏—è"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
    
    # –ì—Ä–∞—Ñ–∏–∫ —Ç–æ—á–Ω–æ—Å—Ç–∏
    ax1.plot(history.history['accuracy'], label='Training Accuracy', linewidth=2)
    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)
    ax1.set_title('Model Accuracy', fontsize=14)
    ax1.set_xlabel('Epoch', fontsize=12)
    ax1.set_ylabel('Accuracy', fontsize=12)
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # –ì—Ä–∞—Ñ–∏–∫ –ø–æ—Ç–µ—Ä—å
    ax2.plot(history.history['loss'], label='Training Loss', linewidth=2)
    ax2.plot(history.history['val_loss'], label='Validation Loss', linewidth=2)
    ax2.set_title('Model Loss', fontsize=14)
    ax2.set_xlabel('Epoch', fontsize=12)
    ax2.set_ylabel('Loss', fontsize=12)
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()

def get_all_predictions_modern(model, dataset):
    """–ü–æ–ª—É—á–∞–µ—Ç –≤—Å–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏ –º–µ—Ç–∫–∏ –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞"""
    print("üîÑ –°–æ–±–∏—Ä–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏ –º–µ—Ç–∫–∏...")
    
    all_preds = []
    all_true_labels = []
    
    for batch_idx, (images, labels) in enumerate(dataset):
        batch_preds = model.predict(images, verbose=0)
        all_preds.append(batch_preds)
        all_true_labels.append(labels.numpy())
        
        if (batch_idx + 1) % 10 == 0:
            print(f"üì¶ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –±–∞—Ç—á–µ–π: {batch_idx + 1}")
    
    all_preds = np.concatenate(all_preds, axis=0)
    all_true_labels = np.concatenate(all_true_labels, axis=0)
    
    print(f"‚úÖ –°–æ–±—Ä–∞–Ω–æ {len(all_preds)} –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π")
    return all_preds, all_true_labels

def safe_confusion_matrix_analysis(model, dataset, class_names):
    """–ê–Ω–∞–ª–∏–∑ confusion matrix —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö –∫–ª–∞—Å—Å–æ–≤"""
    print("üìä –ó–ê–ü–£–°–ö–ê–ï–ú CONFUSION MATRIX –ê–ù–ê–õ–ò–ó...")
    
    preds, true_labels = get_all_predictions_modern(model, dataset)
    
    if len(true_labels.shape) == 1:
        true_classes = true_labels
    else:
        true_classes = np.argmax(true_labels, axis=1)
    
    preds_classes = np.argmax(preds, axis=1)
    
    present_true_classes = np.unique(true_classes)
    present_class_indices = sorted(present_true_classes)
    present_class_names = [class_names[i] for i in present_class_indices]
    
    print(f"üìã –ü—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –∫–ª–∞—Å—Å—ã: {present_class_names}")
    
    cm = confusion_matrix(true_classes, preds_classes, labels=present_class_indices)
    
    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
    plt.figure(figsize=(max(8, len(present_class_names)), max(6, len(present_class_names))))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=present_class_names, 
                yticklabels=present_class_names,
                cbar_kws={'label': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'})
    plt.xlabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∫–ª–∞—Å—Å—ã')
    plt.ylabel('–ò—Å—Ç–∏–Ω–Ω—ã–µ –∫–ª–∞—Å—Å—ã')
    plt.title(f'Confusion Matrix ({len(present_class_names)} –∏–∑ {len(class_names)} –∫–ª–∞—Å—Å–æ–≤)')
    plt.xticks(rotation=45)
    plt.yticks(rotation=0)
    plt.tight_layout()
    plt.show()
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    total_samples = len(true_classes)
    accuracy = np.sum(preds_classes == true_classes) / total_samples
    
    print(f"\nüìà –î–ï–¢–ê–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    print(f"–í—Å–µ–≥–æ –ø—Ä–∏–º–µ—Ä–æ–≤: {total_samples}")
    print(f"–û–±—â–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {accuracy:.4f}")
    
    print(f"\nüéØ –¢–û–ß–ù–û–°–¢–¨ –ü–û –ö–õ–ê–°–°–ê–ú:")
    for i, class_idx in enumerate(present_class_indices):
        class_name = class_names[class_idx]
        correct = cm[i, i]
        total = np.sum(cm[i, :])
        accuracy = correct / total if total > 0 else 0
        print(f"  {class_name}: {accuracy:.4f} ({correct}/{total})")
    
    print(f"\nüìä CLASSIFICATION REPORT:")
    print(classification_report(true_classes, preds_classes, 
                              labels=present_class_indices,
                              target_names=present_class_names, 
                              digits=4))
    
    return cm, present_class_names

def test_random_predictions_modern(model, dataset, class_names, num_samples=12):
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–ª—É—á–∞–π–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ (–≤–µ—Ä—Å–∏—è –¥–ª—è sparse labels)"""
    all_images = []
    all_labels = []
    
    for images, labels in dataset:
        all_images.append(images.numpy())
        all_labels.append(labels.numpy())
    
    all_images = np.concatenate(all_images, axis=0)
    all_labels = np.concatenate(all_labels, axis=0)
    
    total_samples = len(all_images)
    indices = np.random.choice(total_samples, min(num_samples, total_samples), replace=False)
    
    selected_images = all_images[indices]
    selected_labels = all_labels[indices]
    
    predictions = model.predict(selected_images, verbose=0)
    predicted_classes = np.argmax(predictions, axis=1)
    true_classes = selected_labels  # sparse labels
    
    cols = 4
    rows = (num_samples + cols - 1) // cols
    fig, axes = plt.subplots(rows, cols, figsize=(20, 5 * rows))
    
    if rows == 1:
        axes = axes.reshape(1, -1)
    elif rows > 1 and cols == 1:
        axes = axes.reshape(-1, 1)
    
    correct = 0
    for i, idx in enumerate(indices):
        if rows == 1:
            ax = axes[i] if cols > 1 else axes
        else:
            row_idx = i // cols
            col_idx = i % cols
            ax = axes[row_idx, col_idx]
        
        image = selected_images[i].copy()
        image[..., 0] += 103.939
        image[..., 1] += 116.779  
        image[..., 2] += 123.68
        image = np.clip(image, 0, 255).astype('uint8')
        image = image[..., ::-1]  # BGR to RGB
        
        ax.imshow(image)
        
        true_class = class_names[true_classes[i]]
        pred_class = class_names[predicted_classes[i]]
        confidence = np.max(predictions[i])
        
        color = 'green' if true_class == pred_class else 'red'
        if true_class == pred_class:
            correct += 1
            
        ax.set_title(f"True: {true_class}\nPred: {pred_class}\nConf: {confidence:.2f}", 
                    color=color, fontsize=10)
        ax.axis('off')
    
    for i in range(len(indices), rows * cols):
        if rows == 1:
            if cols > 1:
                axes[i].axis('off')
        else:
            row_idx = i // cols
            col_idx = i % cols
            axes[row_idx, col_idx].axis('off')
    
    plt.tight_layout()
    plt.show()
    
    accuracy = correct / len(indices) * 100
    print(f"üìä –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ {len(indices)} —Å–ª—É—á–∞–π–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–∞—Ö: {correct}/{len(indices)} ({accuracy:.1f}%)")
    
    return correct, accuracy