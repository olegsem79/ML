# optuna_optimizer.py
import optuna
from optuna.integration import TFKerasPruningCallback
import tensorflow as tf
from tensorflow.keras.applications import ResNet50, EfficientNetV2S, EfficientNetV2M, EfficientNetV2L
from tensorflow.keras import Model
from tensorflow.keras.layers import (GlobalAveragePooling2D, Dense, Dropout, 
                                   BatchNormalization, Activation)
from tensorflow.keras.regularizers import l2
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
import os
import datetime
from tensorflow.keras.callbacks import TensorBoard

# üîß –°–õ–û–í–ê–†–¨ MODELS:
MODELS = {
    'EfficientNetV2S': EfficientNetV2S,
    'EfficientNetV2M': EfficientNetV2M, 
    'EfficientNetV2L': EfficientNetV2L,
    'ResNet50': ResNet50,
}

def setup_environment():
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è Optuna"""
    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
    os.environ['TF_XLA_FLAGS'] = '--tf_xla_auto_jit=0'
    tf.get_logger().setLevel('ERROR')

def residual_block(x, units, dropout_rate=0.5, l2_reg=1e-5, activation='relu'):
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π residual block –¥–ª—è –Ω–µ–±–æ–ª—å—à–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤"""
    x = Dense(units, kernel_regularizer=l2(l2_reg))(x)
    x = BatchNormalization()(x)
    x = Activation(activation)(x)
    x = Dropout(dropout_rate)(x)
    return x

def create_optuna_model(trial, num_classes, model_name='EfficientNetV2S', height=224, width=224):
    """–°–æ–∑–¥–∞–µ—Ç –º–æ–¥–µ–ª—å —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç Optuna"""
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ—Ç Optuna
    units_2 = trial.suggest_categorical('units_2', [128, 256]) 
    units_3 = trial.suggest_categorical('units_3', [64, 128])
    dropout_2 = trial.suggest_categorical('dropout_2', [0.4, 0.5, 0.6])
    dropout_3 = trial.suggest_categorical('dropout_3', [0.2, 0.3, 0.4])
    l2_reg = trial.suggest_categorical('l2_reg', [1e-5, 1e-4, 1e-3])
    learning_rate = trial.suggest_categorical('learning_rate', [1e-5, 1e-4, 1e-3])
    activation = trial.suggest_categorical('activation', ['relu', 'elu', 'selu'])

    # –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å
    inputs = tf.keras.Input(shape=(height, width, 3))
    base_model = MODELS[model_name](
        weights='imagenet',
        include_top=False,
        input_shape=(height, width, 3)
    )
    base_model.trainable = False
    x = base_model(inputs, training=False)
    
    # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
    x = GlobalAveragePooling2D()(x)
    x = residual_block(x, units_2, dropout_2, l2_reg, activation) 
    x = residual_block(x, units_3, dropout_3, l2_reg, activation)
    
    # –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π
    outputs = Dense(num_classes, activation='softmax')(x)
    
    # –ö–æ–º–ø–∏–ª—è—Ü–∏—è
    model = Model(inputs, outputs)
    model.compile(
        optimizer=Adam(learning_rate=learning_rate),
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )
    
    return model

def run_optuna_optimization(
    train_data,
    validation_data, 
    num_classes,
    model_name='EfficientNetV2S',
    n_trials=20,
    height=224,
    width=224
):
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é Hyperparameters —Å –ø–æ–º–æ—â—å—é Optuna"""
    
    setup_environment()
    
    def objective(trial):
        """–¶–µ–ª–µ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è Optuna"""
        model = create_optuna_model(trial, num_classes, model_name, height, width)
        
        history = model.fit(
            train_data,
            epochs=15,
            validation_data=validation_data,
            verbose=1,
            callbacks=[
                EarlyStopping(
                    monitor='val_accuracy',
                    patience=15,
                    restore_best_weights=True,
                    verbose=1
                ),
                TFKerasPruningCallback(trial, 'val_accuracy')
            ]
        )
        
        best_val_accuracy = max(history.history['val_accuracy'])
        return best_val_accuracy

    print("üöÄ –ó–ê–ü–£–°–ö OPTUNA OPTIMIZATION...")
    
    study = optuna.create_study(
        direction='maximize',
        study_name=f'{model_name}_OPTUNA',
        storage='sqlite:///my_optuna_study.db',
        load_if_exists=True
    )

    study.optimize(objective, n_trials=n_trials)

    print("\nüéØ OPTUNA –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê!")
    print(f"üèÜ –õ–£–ß–®–ò–ï –ü–ê–†–ê–ú–ï–¢–†–´:")
    print(f"  Accuracy: {study.best_value:.4f}")
    for key, value in study.best_params.items():
        print(f"    {key}: {value}")

    return study

def create_final_model(study, num_classes, model_name='EfficientNetV2S', height=224, width=224):
    """–°–æ–∑–¥–∞–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å —Å –ª—É—á—à–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏"""
    print("\nüîß –°–û–ó–î–ê–ï–ú –§–ò–ù–ê–õ–¨–ù–£–Æ –ù–ï –û–ë–£–ß–ï–ù–ù–£–Æ –ú–û–î–ï–õ–¨...")
    best_model = create_optuna_model(study.best_trial, num_classes, model_name, height, width)
    best_model.summary()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å —Å –ª—É—á—à–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    best_model.save('model_optuna_best_params.keras')
    print("üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∫–∞–∫ 'model_optuna_best_params.keras'")
    
    return best_model

def visualize_optuna_results(study):
    """–í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã Optuna"""
    print("\nüìà –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø –†–ï–ó–£–õ–¨–¢–ê–¢–û–í...")
    
    try:
        # 1. –ì—Ä–∞—Ñ–∏–∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        fig1 = optuna.visualization.plot_optimization_history(study)
        fig1.show()

        # 2. –í–∞–∂–Ω–æ—Å—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        fig2 = optuna.visualization.plot_param_importances(study)
        fig2.show()

        # 3. –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
        fig3 = optuna.visualization.plot_parallel_coordinate(study)
        fig3.show()

        # 4. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        fig4 = optuna.visualization.plot_contour(study)
        fig4.show()

        # 5. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π
        fig5 = optuna.visualization.plot_slice(study)
        fig5.show()

        # 6. Timeline –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        fig6 = optuna.visualization.plot_timeline(study)
        fig6.show()
        
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")

def train_final_model(
    model,
    train_data,
    validation_data,
    class_weights=None,
    epochs=70,
    model_name='best_model'
):
    """–û–±—É—á–∞–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å —Å –ª—É—á—à–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏"""
    
    # Callbacks
    log_dir = os.path.join("logs", "fit", datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))
    os.makedirs(log_dir, exist_ok=True)
    
    tensorboard_callback = TensorBoard(
        log_dir=log_dir,
        histogram_freq=1,
        write_graph=True,
        write_images=False,
        update_freq='epoch',
        profile_batch=0
    )
    
    callbacks = [
        tf.keras.callbacks.EarlyStopping(
            monitor='val_accuracy', 
            patience=15, 
            restore_best_weights=True, 
            verbose=1
        ),
        tf.keras.callbacks.ModelCheckpoint(
            f'{model_name}_callback.keras', 
            monitor='val_accuracy', 
            save_best_only=True, 
            verbose=1
        ),
        tf.keras.callbacks.ReduceLROnPlateau(
            monitor='val_loss', 
            patience=7, 
            factor=0.3, 
            verbose=1
        ),
        tensorboard_callback
    ]
    
    print("üöÄ –û–ë–£–ß–ê–ï–ú –§–ò–ù–ê–õ–¨–ù–£–Æ –ú–û–î–ï–õ–¨...")
    history = model.fit(
        train_data,
        epochs=epochs,
        validation_data=validation_data,
        class_weight=class_weights,
        callbacks=callbacks,
        verbose=1
    )
    
    return history

def evaluate_model(model, validation_data, model_name="model"):
    """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç –º–æ–¥–µ–ª—å –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã"""
    print(f"\nüìä –û–¶–ï–ù–ö–ê {model_name.upper()}...")
    val_results = model.evaluate(validation_data, verbose=1)
    val_loss, val_accuracy = val_results[0], val_results[1]
    
    print(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã {model_name}:")
    print(f"   - Validation Accuracy: {val_accuracy:.4f}")
    print(f"   - Validation Loss: {val_loss:.4f}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å —Å accuracy –≤ –∏–º–µ–Ω–∏
    model.save(f'{model_name}_{val_accuracy:.4f}.keras')
    print(f"üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∫–∞–∫ '{model_name}_{val_accuracy:.4f}.keras'")
    
    return val_loss, val_accuracy