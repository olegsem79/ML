{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec34c3c3-9a34-491e-ab96-3457ae9f7116",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'run_optuna_optimization' from 'optuna_optimizer' (/home/oleg/projects/ML/app/optuna_optimizer.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdata_pipeline\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m setup_tensorflow, create_data_pipeline, get_class_weights_from_dataset\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moptuna_optimizer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (run_optuna_optimization, create_final_model, \n\u001b[32m      5\u001b[39m                             train_final_model, evaluate_model, visualize_optuna_results)\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvisualization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (plot_training_history, safe_confusion_matrix_analysis, \n\u001b[32m      7\u001b[39m                          test_random_predictions_modern)\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmain\u001b[39m():\n\u001b[32m     10\u001b[39m     \u001b[38;5;66;03m# –ù–∞—Å—Ç—Ä–æ–π–∫–∞\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'run_optuna_optimization' from 'optuna_optimizer' (/home/oleg/projects/ML/app/optuna_optimizer.py)"
     ]
    }
   ],
   "source": [
    "# main_optuna.py\n",
    "import os\n",
    "from data_pipeline import setup_tensorflow, create_data_pipeline, get_class_weights_from_dataset\n",
    "from optuna_optimizer import (run_optuna_optimization, create_final_model, \n",
    "                            train_final_model, evaluate_model, visualize_optuna_results)\n",
    "from visualization import (plot_training_history, safe_confusion_matrix_analysis, \n",
    "                         test_random_predictions_modern)\n",
    "\n",
    "def main():\n",
    "    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞\n",
    "    setup_tensorflow()\n",
    "    \n",
    "    # –ü—É—Ç–∏\n",
    "    IMAGE_PATH = \"/home/oleg/projects/datasets/construction\"\n",
    "    print(f\"–°–æ–¥–µ—Ä–∂–∏–º–æ–µ –ø–∞–ø–∫–∏: {os.listdir(IMAGE_PATH)}\")\n",
    "    \n",
    "    # –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞\n",
    "    train_data, validation_data, train_data_raw, class_names, num_classes = create_data_pipeline(\n",
    "        image_path=IMAGE_PATH,\n",
    "        height=224,\n",
    "        width=224, \n",
    "        batch_size=32\n",
    "    )\n",
    "    \n",
    "    # –†–∞—Å—á–µ—Ç –≤–µ—Å–æ–≤ –∫–ª–∞—Å—Å–æ–≤\n",
    "    print(\"üéØ –†–∞—Å—á–µ—Ç –≤–µ—Å–æ–≤ –∫–ª–∞—Å—Å–æ–≤...\")\n",
    "    class_weights = get_class_weights_from_dataset(train_data_raw, class_names)\n",
    "    \n",
    "    # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è Optuna\n",
    "    study = run_optuna_optimization(\n",
    "        train_data=train_data,\n",
    "        validation_data=validation_data,\n",
    "        num_classes=num_classes,\n",
    "        model_name='EfficientNetV2S',\n",
    "        n_trials=20\n",
    "    )\n",
    "    \n",
    "    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ Optuna\n",
    "    visualize_optuna_results(study)\n",
    "    \n",
    "    # –°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏\n",
    "    best_model = create_final_model(study, num_classes)\n",
    "    \n",
    "    # –û–±—É—á–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏\n",
    "    final_history = train_final_model(\n",
    "        model=best_model,\n",
    "        train_data=train_data,\n",
    "        validation_data=validation_data,\n",
    "        class_weights=class_weights,\n",
    "        epochs=70\n",
    "    )\n",
    "    \n",
    "    # –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏\n",
    "    val_loss, val_accuracy = evaluate_model(best_model, validation_data, \"trained_optuna_model\")\n",
    "    \n",
    "    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "    plot_training_history(final_history)\n",
    "    safe_confusion_matrix_analysis(best_model, validation_data, class_names)\n",
    "    test_random_predictions_modern(best_model, validation_data, class_names)\n",
    "    \n",
    "    print(\"üéâ –í–°–ï –ó–ê–î–ê–ß–ò –í–´–ü–û–õ–ù–ï–ù–´!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd3b5c70-d634-4a00-a151-e648bf20fbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ –°–û–ó–î–ê–ï–ú –ü–ê–ô–ü–õ–ê–ô–ù...\n",
      "Found 4990 files belonging to 8 classes.\n",
      "Using 3992 files for training.\n",
      "Found 4990 files belonging to 8 classes.\n",
      "Using 998 files for validation.\n",
      "Labels shape: (32,)\n",
      "Labels: [0 5 1 5 5 6 2 6 6 0]\n",
      "üè∑Ô∏è –ö–ª–∞—Å—Å—ã: ['bulldozer', 'car', 'dump_truck', 'excavator', 'ice_rink', 'mining_loader', 'person', 'truck_crane']\n",
      "üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞:\n",
      "Shape: (32, 224, 224, 3)\n",
      "Data range: 0.000 to 255.000\n",
      "Mean: 112.395\n",
      "‚úÖ –ü–∞–π–ø–ª–∞–π–Ω —Å–æ–∑–¥–∞–Ω!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-25 20:01:09.952428: W tensorflow/core/kernels/data/cache_dataset_ops.cc:916] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞\n",
    "setup_tensorflow()\n",
    "train_data, validation_data, train_data_raw, class_names, num_classes = create_data_pipeline(IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1018c6c-5f5b-43f6-92a4-d0c66a7a199e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# –°–æ–∑–¥–∞–Ω–∏–µ –∏ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m model = \u001b[43mcreate_model\u001b[49m(num_classes)\n\u001b[32m      3\u001b[39m history = train_model(model, train_data, validation_data, class_weights)\n",
      "\u001b[31mNameError\u001b[39m: name 'create_model' is not defined"
     ]
    }
   ],
   "source": [
    "# –°–æ–∑–¥–∞–Ω–∏–µ –∏ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "model = create_model(num_classes)\n",
    "history = train_model(model, train_data, validation_data, class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47169866-146b-42e0-8d39-dc61cc8e876f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensflow",
   "language": "python",
   "name": "tensflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
