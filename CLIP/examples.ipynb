{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731beaf3-36c8-452a-ab7f-f3e35d405865",
   "metadata": {},
   "outputs": [],
   "source": [
    "üìä 1. –ê–ù–ù–û–¢–ê–¶–ò–Ø –ò –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–Ø –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô\n",
    "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Ä–∞–∑–º–µ—Ç–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤\n",
    "python\n",
    "def auto_annotate_dataset(image_folder, candidate_labels):\n",
    "    \"\"\"–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –±–µ–∑ —Ä—É—á–Ω–æ–π —Ä–∞–∑–º–µ—Ç–∫–∏\"\"\"\n",
    "    \n",
    "    model, processor = load_clip_model()\n",
    "    results = []\n",
    "    \n",
    "    for img_path in Path(image_folder).glob(\"*.jpg\"):\n",
    "        image = Image.open(img_path)\n",
    "        \n",
    "        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å CLIP\n",
    "        best_label, confidence = classify_image(image, candidate_labels, model, processor)\n",
    "        \n",
    "        results.append({\n",
    "            'image_path': str(img_path),\n",
    "            'predicted_label': best_label,\n",
    "            'confidence': confidence,\n",
    "            'candidate_labels': candidate_labels\n",
    "        })\n",
    "    \n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏\n",
    "    pd.DataFrame(results).to_csv('auto_annotations.csv', index=False)\n",
    "    return results\n",
    "\n",
    "# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\n",
    "candidate_labels = [\n",
    "    \"cat\", \"dog\", \"bird\", \"car\", \"tree\", \"person\", \n",
    "    \"building\", \"food\", \"mountain\", \"beach\"\n",
    "]\n",
    "\n",
    "auto_annotate_dataset(\"raw_images/\", candidate_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c253e7db-afc5-4f28-94b4-9ba5b2d6ddaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞ –ø–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é\n",
    "python\n",
    "def filter_dataset_by_content(image_paths, required_content, threshold=0.3):\n",
    "    \"\"\"–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é\"\"\"\n",
    "    \n",
    "    model, processor = load_clip_model()\n",
    "    filtered_images = []\n",
    "    \n",
    "    for img_path in image_paths:\n",
    "        image = Image.open(img_path)\n",
    "        best_label, confidence = classify_image(image, [required_content], model, processor)\n",
    "        \n",
    "        if confidence > threshold:\n",
    "            filtered_images.append({\n",
    "                'path': img_path,\n",
    "                'content': best_label,\n",
    "                'confidence': confidence\n",
    "            })\n",
    "    \n",
    "    return filtered_images\n",
    "\n",
    "# –ü—Ä–∏–º–µ—Ä: –æ—Ç–æ–±—Ä–∞—Ç—å —Ç–æ–ª—å–∫–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –∫–æ—Ç–∞–º–∏\n",
    "cat_images = filter_dataset_by_content(all_images, \"a photo of a cat\", 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a457f952-5c38-4536-995d-6dcd6573d1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. –≠–õ–ï–ö–¢–†–û–ù–ù–ê–Ø –ö–û–ú–ú–ï–†–¶–ò–Ø –ò –¢–û–í–ê–†–´\n",
    "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Ç–µ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–æ–≤\n",
    "python\n",
    "def auto_tag_products(product_images, product_categories):\n",
    "    \"\"\"–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Ç–µ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-–º–∞–≥–∞–∑–∏–Ω–∞\"\"\"\n",
    "    \n",
    "    model, processor = load_clip_model()\n",
    "    product_tags = {}\n",
    "    \n",
    "    for product_id, image_path in product_images.items():\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        # –ú—É–ª—å—Ç–∏-–∫–ª–∞—Å—Å–æ–≤–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è\n",
    "        tags_with_scores = {}\n",
    "        for category in product_categories:\n",
    "            _, confidence = classify_image(image, [category], model, processor)\n",
    "            if confidence > 0.2:  # –ü–æ—Ä–æ–≥ –¥–ª—è —Ç–µ–≥–∞\n",
    "                tags_with_scores[category] = confidence\n",
    "        \n",
    "        product_tags[product_id] = tags_with_scores\n",
    "    \n",
    "    return product_tags\n",
    "\n",
    "# –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–ª—è –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-–º–∞–≥–∞–∑–∏–Ω–∞\n",
    "product_categories = [\n",
    "    \"electronics\", \"clothing\", \"home decor\", \"sports equipment\",\n",
    "    \"books\", \"beauty products\", \"toys\", \"furniture\",\n",
    "    \"kitchenware\", \"jewelry\", \"shoes\", \"accessories\"\n",
    "]\n",
    "\n",
    "product_tags = auto_tag_products(product_images, product_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659db700-c0f9-4642-aceb-b5c129a31138",
   "metadata": {},
   "outputs": [],
   "source": [
    "–ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö —Ç–æ–≤–∞—Ä–æ–≤\n",
    "python\n",
    "def find_similar_products(query_image, product_database, top_k=5):\n",
    "    \"\"\"–ü–æ–∏—Å–∫ –≤–∏–∑—É–∞–ª—å–Ω–æ –ø–æ—Ö–æ–∂–∏—Ö —Ç–æ–≤–∞—Ä–æ–≤\"\"\"\n",
    "    \n",
    "    model, processor = load_clip_model()\n",
    "    \n",
    "    # –≠–º–±–µ–¥–¥–∏–Ω–≥ –∑–∞–ø—Ä–æ—Å–∞\n",
    "    query_embedding = get_image_embedding(query_image, model, processor)\n",
    "    \n",
    "    similarities = []\n",
    "    for product_id, product_image in product_database.items():\n",
    "        product_embedding = get_image_embedding(product_image, model, processor)\n",
    "        similarity = cosine_similarity(query_embedding, product_embedding)\n",
    "        similarities.append((product_id, similarity))\n",
    "    \n",
    "    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Å—Ö–æ–∂–µ—Å—Ç–∏\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    return similarities[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1ee4db-a991-43b6-bb5f-12dfb0e61199",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. –ú–ï–î–ò–¶–ò–ù–ê –ò –ó–î–û–†–û–í–¨–ï\n",
    "–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n",
    "python\n",
    "def medical_image_analysis(medical_images, analysis_types):\n",
    "    \"\"\"–ê–Ω–∞–ª–∏–∑ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\"\"\"\n",
    "    \n",
    "    model, processor = load_clip_model()\n",
    "    results = []\n",
    "    \n",
    "    medical_conditions = [\n",
    "        \"healthy skin\", \"skin rash\", \"skin infection\", \"allergic reaction\",\n",
    "        \"bone fracture\", \"normal x-ray\", \"dental cavity\", \"healthy teeth\",\n",
    "        \"eye infection\", \"normal eye\", \"ear infection\", \"healthy ear\"\n",
    "    ]\n",
    "    \n",
    "    for img_path in medical_images:\n",
    "        image = Image.open(img_path)\n",
    "        \n",
    "        # –ê–Ω–∞–ª–∏–∑ –Ω–∞ —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è\n",
    "        condition_scores = {}\n",
    "        for condition in medical_conditions:\n",
    "            _, confidence = classify_image(image, [condition], model, processor)\n",
    "            condition_scores[condition] = confidence\n",
    "        \n",
    "        # –õ—É—á—à–∏–π –¥–∏–∞–≥–Ω–æ–∑\n",
    "        best_condition = max(condition_scores, key=condition_scores.get)\n",
    "        \n",
    "        results.append({\n",
    "            'image': img_path,\n",
    "            'predicted_condition': best_condition,\n",
    "            'confidence': condition_scores[best_condition],\n",
    "            'all_scores': condition_scores\n",
    "        })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9b9470-c866-4053-934d-1008c1861cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "4. –≠–ö–û–õ–û–ì–ò–Ø –ò –°–ï–õ–¨–°–ö–û–ï –•–û–ó–Ø–ô–°–¢–í–û\n",
    "–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ä–∞—Å—Ç–µ–Ω–∏–π –∏ –∂–∏–≤–æ—Ç–Ω—ã—Ö\n",
    "python\n",
    "def biodiversity_analysis(wildlife_images):\n",
    "    \"\"\"–ê–Ω–∞–ª–∏–∑ –±–∏–æ—Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è –ø–æ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è–º\"\"\"\n",
    "    \n",
    "    species_categories = [\n",
    "        \"oak tree\", \"pine tree\", \"maple tree\", \"birch tree\",\n",
    "        \"sparrow\", \"robin\", \"eagle\", \"owl\",\n",
    "        \"deer\", \"fox\", \"rabbit\", \"squirrel\",\n",
    "        \"rose flower\", \"sunflower\", \"tulip\", \"daisy\",\n",
    "        \"butterfly\", \"bee\", \"ladybug\", \"dragonfly\"\n",
    "    ]\n",
    "    \n",
    "    biodiversity_data = {}\n",
    "    \n",
    "    for img_path in wildlife_images:\n",
    "        image = Image.open(img_path)\n",
    "        \n",
    "        species_detected = []\n",
    "        for species in species_categories:\n",
    "            _, confidence = classify_image(image, [species], model, processor)\n",
    "            if confidence > 0.3:\n",
    "                species_detected.append((species, confidence))\n",
    "        \n",
    "        biodiversity_data[img_path] = species_detected\n",
    "    \n",
    "    return biodiversity_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3a7923-9e42-47c8-825b-1c9eb06a144d",
   "metadata": {},
   "outputs": [],
   "source": [
    "–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ–ª—å—Ö–æ–∑–∫—É–ª—å—Ç—É—Ä\n",
    "python\n",
    "def crop_health_monitoring(field_images):\n",
    "    \"\"\"–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∑–¥–æ—Ä–æ–≤—å—è —Å–µ–ª—å—Å–∫–æ—Ö–æ–∑—è–π—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∫—É–ª—å—Ç—É—Ä\"\"\"\n",
    "    \n",
    "    health_conditions = [\n",
    "        \"healthy wheat field\", \"wheat with rust disease\",\n",
    "        \"healthy corn plants\", \"corn with blight\",\n",
    "        \"healthy tomato plants\", \"tomatoes with late blight\", \n",
    "        \"well irrigated soil\", \"dry soil needing water\",\n",
    "        \"fertile soil\", \"nutrient deficient soil\"\n",
    "    ]\n",
    "    \n",
    "    field_reports = []\n",
    "    \n",
    "    for location, img_path in field_images.items():\n",
    "        image = Image.open(img_path)\n",
    "        \n",
    "        condition_scores = {}\n",
    "        for condition in health_conditions:\n",
    "            _, confidence = classify_image(image, [condition], model, processor)\n",
    "            condition_scores[condition] = confidence\n",
    "        \n",
    "        field_reports.append({\n",
    "            'location': location,\n",
    "            'dominant_condition': max(condition_scores, key=condition_scores.get),\n",
    "            'health_score': condition_scores[\"healthy wheat field\"],  # –ò–Ω–¥–µ–∫—Å –∑–¥–æ—Ä–æ–≤—å—è\n",
    "            'all_conditions': condition_scores\n",
    "        })\n",
    "    \n",
    "    return field_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080a089b-e9de-41bc-a45e-4d0aee55ae83",
   "metadata": {},
   "outputs": [],
   "source": [
    "–ê–Ω–∞–ª–∏–∑ –≥–æ—Ä–æ–¥—Å–∫–æ–π –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã\n",
    "python\n",
    "def urban_analysis(city_images):\n",
    "    \"\"\"–ê–Ω–∞–ª–∏–∑ –≥–æ—Ä–æ–¥—Å–∫–æ–π —Å—Ä–µ–¥—ã –∏ –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã\"\"\"\n",
    "    \n",
    "    urban_categories = [\n",
    "        \"residential area with houses\", \"commercial district with shops\",\n",
    "        \"industrial zone with factories\", \"park with trees and grass\",\n",
    "        \"pedestrian street with people walking\", \"road with heavy traffic\",\n",
    "        \"public transportation station\", \"bicycle lane with cyclists\",\n",
    "        \"parking lot with cars\", \"construction site with workers\",\n",
    "        \"clean and well-maintained area\", \"area needing maintenance\"\n",
    "    ]\n",
    "    \n",
    "    city_data = []\n",
    "    \n",
    "    for location, img_path in city_images.items():\n",
    "        image = Image.open(img_path)\n",
    "        \n",
    "        urban_scores = {}\n",
    "        for category in urban_categories:\n",
    "            _, confidence = classify_image(image, [category], model, processor)\n",
    "            urban_scores[category] = confidence\n",
    "        \n",
    "        city_data.append({\n",
    "            'location': location,\n",
    "            'area_type': max(urban_scores, key=urban_scores.get),\n",
    "            'traffic_level': urban_scores.get(\"road with heavy traffic\", 0),\n",
    "            'green_space': urban_scores.get(\"park with trees and grass\", 0),\n",
    "            'commercial_presence': urban_scores.get(\"commercial district with shops\", 0)\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(city_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5515e098-a47f-44e0-b489-cc5ab76fcfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–π –∏—Å–∫—É—Å—Å—Ç–≤–∞\n",
    "python\n",
    "def art_style_classification(artwork_images):\n",
    "    \"\"\"–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å—Ç–∏–ª–µ–π –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–π –∏—Å–∫—É—Å—Å—Ç–≤–∞\"\"\"\n",
    "    \n",
    "    art_styles = [\n",
    "        \"renaissance painting\", \"baroque art\", \"impressionist painting\",\n",
    "        \"cubist artwork\", \"abstract art\", \"surrealist painting\",\n",
    "        \"pop art\", \"modern art\", \"contemporary art\",\n",
    "        \"oil painting\", \"watercolor painting\", \"sculpture\",\n",
    "        \"photography\", \"digital art\", \"street art\"\n",
    "    ]\n",
    "    \n",
    "    artwork_analysis = []\n",
    "    \n",
    "    for artwork in artwork_images:\n",
    "        image = Image.open(artwork['path'])\n",
    "        \n",
    "        style_scores = {}\n",
    "        for style in art_styles:\n",
    "            _, confidence = classify_image(image, [style], model, processor)\n",
    "            style_scores[style] = confidence\n",
    "        \n",
    "        artwork_analysis.append({\n",
    "            'artwork_id': artwork['id'],\n",
    "            'title': artwork['title'],\n",
    "            'predicted_style': max(style_scores, key=style_scores.get),\n",
    "            'style_confidence': max(style_scores.values()),\n",
    "            'all_style_scores': style_scores\n",
    "        })\n",
    "    \n",
    "    return artwork_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecf0e71-30d8-4dd3-954c-c601c1894f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "7. –°–û–¶–ò–ê–õ–¨–ù–´–ï –°–ï–¢–ò –ò –ö–û–ù–¢–ï–ù–¢\n",
    "–ú–æ–¥–µ—Ä–∞—Ü–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞\n",
    "python\n",
    "def content_moderation(user_images, moderation_categories):\n",
    "    \"\"\"–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –º–æ–¥–µ—Ä–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞\"\"\"\n",
    "    \n",
    "    model, processor = load_clip_model()\n",
    "    moderation_results = []\n",
    "    \n",
    "    default_categories = [\n",
    "        \"safe and appropriate content\", \"violent content\",\n",
    "        \"inappropriate adult content\", \"hate speech imagery\",\n",
    "        \"dangerous activities\", \"alcohol or drugs\",\n",
    "        \"weapons or firearms\", \"spam content\"\n",
    "    ]\n",
    "    \n",
    "    categories = moderation_categories or default_categories\n",
    "    \n",
    "    for user_id, img_path in user_images.items():\n",
    "        image = Image.open(img_path)\n",
    "        \n",
    "        moderation_scores = {}\n",
    "        for category in categories:\n",
    "            _, confidence = classify_image(image, [category], model, processor)\n",
    "            moderation_scores[category] = confidence\n",
    "        \n",
    "        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –º–æ–¥–µ—Ä–∞—Ü–∏–∏\n",
    "        safe_score = moderation_scores.get(\"safe and appropriate content\", 0)\n",
    "        max_unsafe = max([moderation_scores.get(cat, 0) for cat in categories if cat != \"safe and appropriate content\"])\n",
    "        \n",
    "        status = \"approved\" if safe_score > max_unsafe else \"needs_review\"\n",
    "        \n",
    "        moderation_results.append({\n",
    "            'user_id': user_id,\n",
    "            'image_path': img_path,\n",
    "            'moderation_status': status,\n",
    "            'safe_score': safe_score,\n",
    "            'highest_concern': max(moderation_scores, key=moderation_scores.get),\n",
    "            'all_scores': moderation_scores\n",
    "        })\n",
    "    \n",
    "    return moderation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab91f4c-abbd-4411-a456-d769197725c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞\n",
    "python\n",
    "def auto_caption_social_media(images, style=\"instagram\"):\n",
    "    \"\"\"–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –ø–æ–¥–ø–∏—Å–µ–π –¥–ª—è —Å–æ—Ü—Å–µ—Ç–µ–π\"\"\"\n",
    "    \n",
    "    caption_templates = {\n",
    "        \"instagram\": [\n",
    "            \"Beautiful moment captured üì∏\",\n",
    "            \"Amazing view! üòç\", \n",
    "            \"Living the best life üåü\",\n",
    "            \"Nature at its finest üåø\",\n",
    "            \"City vibes üèôÔ∏è\",\n",
    "            \"Food heaven üçï\",\n",
    "            \"Adventure time! üó∫Ô∏è\"\n",
    "        ],\n",
    "        \"twitter\": [\n",
    "            \"Check this out!\",\n",
    "            \"Interesting find üîç\",\n",
    "            \"Thoughts on this?\",\n",
    "            \"Can't believe this!\",\n",
    "            \"Beautiful scene spotted\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    templates = caption_templates.get(style, caption_templates[\"instagram\"])\n",
    "    captions = []\n",
    "    \n",
    "    for img_path in images:\n",
    "        image = Image.open(img_path)\n",
    "        \n",
    "        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
    "        content_categories = [\"nature\", \"city\", \"food\", \"people\", \"animals\", \"travel\"]\n",
    "        content_scores = {}\n",
    "        \n",
    "        for category in content_categories:\n",
    "            _, confidence = classify_image(image, [category], model, processor)\n",
    "            content_scores[category] = confidence\n",
    "        \n",
    "        dominant_content = max(content_scores, key=content_scores.get)\n",
    "        \n",
    "        # –í—ã–±–∏—Ä–∞–µ–º –ø–æ–¥—Ö–æ–¥—è—â–∏–π —à–∞–±–ª–æ–Ω\n",
    "        if dominant_content == \"nature\":\n",
    "            caption = \"Beautiful nature shot! üåø\"\n",
    "        elif dominant_content == \"food\":\n",
    "            caption = \"Delicious food alert! üçï\"\n",
    "        elif dominant_content == \"city\":\n",
    "            caption = \"Urban exploration üèôÔ∏è\"\n",
    "        else:\n",
    "            caption = np.random.choice(templates)\n",
    "        \n",
    "        captions.append({\n",
    "            'image': img_path,\n",
    "            'auto_caption': caption,\n",
    "            'detected_content': dominant_content,\n",
    "            'content_confidence': content_scores[dominant_content]\n",
    "        })\n",
    "    \n",
    "    return captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52efeff-4c34-44aa-a796-b90669739d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "–ê–Ω–∞–ª–∏–∑ –Ω–∞—É—á–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n",
    "python\n",
    "def scientific_image_analysis(research_images, domain=\"biology\"):\n",
    "    \"\"\"–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –Ω–∞—É—á–Ω—ã—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π\"\"\"\n",
    "    \n",
    "    domain_categories = {\n",
    "        \"biology\": [\n",
    "            \"microscopic cell structure\", \"bacteria culture\", \n",
    "            \"plant tissue sample\", \"animal tissue sample\",\n",
    "            \"DNA gel electrophoresis\", \"protein crystallization\",\n",
    "            \"healthy biological sample\", \"infected biological sample\"\n",
    "        ],\n",
    "        \"astronomy\": [\n",
    "            \"star cluster\", \"galaxy\", \"nebula\", \"planet\",\n",
    "            \"solar system object\", \"deep space phenomenon\",\n",
    "            \"telescope observation\", \"satellite imagery\"\n",
    "        ],\n",
    "        \"materials\": [\n",
    "            \"crystal structure\", \"metal surface\", \n",
    "            \"polymer material\", \"composite material\",\n",
    "            \"nanomaterial\", \"semiconductor\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    categories = domain_categories.get(domain, domain_categories[\"biology\"])\n",
    "    analysis_results = []\n",
    "    \n",
    "    for image_id, img_path in research_images.items():\n",
    "        image = Image.open(img_path)\n",
    "        \n",
    "        category_scores = {}\n",
    "        for category in categories:\n",
    "            _, confidence = classify_image(image, [category], model, processor)\n",
    "            category_scores[category] = confidence\n",
    "        \n",
    "        analysis_results.append({\n",
    "            'image_id': image_id,\n",
    "            'domain': domain,\n",
    "            'primary_category': max(category_scores, key=category_scores.get),\n",
    "            'category_confidence': max(category_scores.values()),\n",
    "            'full_analysis': category_scores\n",
    "        })\n",
    "    \n",
    "    return analysis_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93bcf79-c04f-4283-b800-41e0c550d366",
   "metadata": {},
   "outputs": [],
   "source": [
    "–ê–Ω–∞–ª–∏–∑ –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤\n",
    "python\n",
    "def competitor_visual_analysis(competitor_images):\n",
    "    \"\"\"–ê–Ω–∞–ª–∏–∑ –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤\"\"\"\n",
    "    \n",
    "    business_categories = [\n",
    "        \"professional business setting\", \"casual work environment\",\n",
    "        \"high-end luxury product\", \"affordable consumer product\", \n",
    "        \"innovative technology\", \"traditional product\",\n",
    "        \"corporate branding\", \"creative marketing content\",\n",
    "        \"customer interaction\", \"product demonstration\"\n",
    "    ]\n",
    "    \n",
    "    competitor_insights = {}\n",
    "    \n",
    "    for competitor, images in competitor_images.items():\n",
    "        category_scores = {category: 0 for category in business_categories}\n",
    "        total_images = len(images)\n",
    "        \n",
    "        for img_path in images:\n",
    "            image = Image.open(img_path)\n",
    "            \n",
    "            for category in business_categories:\n",
    "                _, confidence = classify_image(image, [category], model, processor)\n",
    "                category_scores[category] += confidence\n",
    "        \n",
    "        # –£—Å—Ä–µ–¥–Ω—è–µ–º scores\n",
    "        for category in category_scores:\n",
    "            category_scores[category] /= total_images\n",
    "        \n",
    "        competitor_insights[competitor] = {\n",
    "            'total_images_analyzed': total_images,\n",
    "            'visual_strategy': max(category_scores, key=category_scores.get),\n",
    "            'category_breakdown': category_scores\n",
    "        }\n",
    "    \n",
    "    return competitor_insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0750f1c-681b-4fcf-b25c-b81d461d8e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "10. –£–ù–ò–í–ï–†–°–ê–õ–¨–ù–´–ô –ò–ù–°–¢–†–£–ú–ï–ù–¢ –î–õ–Ø –õ–Æ–ë–´–• –î–ê–¢–ê–°–ï–¢–û–í\n",
    "python\n",
    "def universal_dataset_analyzer(dataset_path, custom_categories=None):\n",
    "    \"\"\"–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–ª—è –ª—é–±—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\"\"\"\n",
    "    \n",
    "    if custom_categories is None:\n",
    "        custom_categories = [\n",
    "            \"indoor scene\", \"outdoor scene\", \"natural environment\", \n",
    "            \"urban environment\", \"people present\", \"animals present\",\n",
    "            \"text visible\", \"food related\", \"vehicle present\",\n",
    "            \"technology visible\", \"artistic content\", \"document\"\n",
    "        ]\n",
    "    \n",
    "    dataset_analysis = {\n",
    "        'summary': {},\n",
    "        'per_image_analysis': [],\n",
    "        'category_distribution': {cat: 0 for cat in custom_categories}\n",
    "    }\n",
    "    \n",
    "    image_files = list(Path(dataset_path).glob(\"**/*.jpg\")) + \\\n",
    "                  list(Path(dataset_path).glob(\"**/*.png\"))\n",
    "    \n",
    "    for img_path in image_files:\n",
    "        image = Image.open(img_path)\n",
    "        \n",
    "        image_analysis = {'path': str(img_path)}\n",
    "        \n",
    "        for category in custom_categories:\n",
    "            _, confidence = classify_image(image, [category], model, processor)\n",
    "            image_analysis[category] = confidence\n",
    "            \n",
    "            if confidence > 0.5:  # –ü–æ—Ä–æ–≥ –¥–ª—è —É—á–µ—Ç–∞ –≤ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏\n",
    "                dataset_analysis['category_distribution'][category] += 1\n",
    "        \n",
    "        dataset_analysis['per_image_analysis'].append(image_analysis)\n",
    "    \n",
    "    # –°–≤–æ–¥–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n",
    "    total_images = len(image_files)\n",
    "    dataset_analysis['summary'] = {\n",
    "        'total_images': total_images,\n",
    "        'most_common_category': max(dataset_analysis['category_distribution'], \n",
    "                                  key=dataset_analysis['category_distribution'].get),\n",
    "        'category_percentages': {k: v/total_images for k, v in \n",
    "                               dataset_analysis['category_distribution'].items()}\n",
    "    }\n",
    "    \n",
    "    return dataset_analysis\n",
    "üí° –ö–ª—é—á–µ–≤—ã–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ CLIP –¥–ª—è –¥–∞—Ç–∞—Å–µ—Ç–æ–≤:\n",
    "üöÄ –ù—É–ª–µ–≤—ã–µ –≤—ã—Å—Ç—Ä–µ–ª—ã - –ù–µ —Ç—Ä–µ–±—É–µ—Ç —Ä–∞–∑–º–µ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö\n",
    "\n",
    "üéØ –ì–∏–±–∫–æ—Å—Ç—å - –õ–µ–≥–∫–æ –¥–æ–±–∞–≤–ª—è—Ç—å –Ω–æ–≤—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏\n",
    "\n",
    "üìä –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å - –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ç—ã—Å—è—á–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n",
    "\n",
    "üîç –ú—É–ª—å—Ç–∏–¥–æ–º–µ–Ω–Ω–æ—Å—Ç—å - –†–∞–±–æ—Ç–∞–µ—Ç –≤ —Ä–∞–∑–Ω—ã—Ö –æ–±–ª–∞—Å—Ç—è—Ö\n",
    "\n",
    "üí¨ –ï—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —è–∑—ã–∫ - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è –≤–º–µ—Å—Ç–æ —á–∏—Å–ª–æ–≤—ã—Ö –º–µ—Ç–æ–∫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5fd1054-0235-4f1c-b753-1632d8fe16f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       –ú–æ–¥–µ–ª—å                  –û—Å–Ω–æ–≤–Ω–∞—è –∑–∞–¥–∞—á–∞  \\\n",
      "0        CLIP          –°–≤—è–∑—å —Ç–µ–∫—Å—Ç-–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ   \n",
      "1  YOLO-World   –î–µ—Ç–µ–∫—Ü–∏—è –ø–æ —Ç–µ–∫—Å—Ç–æ–≤—ã–º –∑–∞–ø—Ä–æ—Å–∞–º   \n",
      "2      YOLO-E   –¢—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω–∞—è –¥–µ—Ç–µ–∫—Ü–∏—è –æ–±—ä–µ–∫—Ç–æ–≤   \n",
      "3        DINO  –í–∏–∑—É–∞–ª—å–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –±–µ–∑ –º–µ—Ç–æ–∫   \n",
      "\n",
      "                           –¢–∏–ø –æ–±—É—á–µ–Ω–∏—è Zero-shot –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏  \\\n",
      "0       –ö–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–æ–µ (—Ç–µ–∫—Å—Ç-–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ)            ‚úÖ –û—Ç–ª–∏—á–Ω—ã–µ   \n",
      "1       Supervised + —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è             ‚úÖ –•–æ—Ä–æ—à–∏–µ   \n",
      "2  Supervised —Å —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –∫–ª–∞—Å—Å–∞–º–∏        ‚ùå –û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–µ   \n",
      "3           Self-supervised (–±–µ–∑ –º–µ—Ç–æ–∫)             ‚úÖ –•–æ—Ä–æ—à–∏–µ   \n",
      "\n",
      "  –î–µ—Ç–µ–∫—Ü–∏—è –æ–±—ä–µ–∫—Ç–æ–≤     –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –¢—Ä–µ–±—É–µ—Ç —Ä–∞–∑–º–µ—Ç–∫–∏  \\\n",
      "0             ‚ùå –ù–µ—Ç        ‚úÖ –û—Ç–ª–∏—á–Ω–∞—è            ‚ùå –ù–µ—Ç   \n",
      "1        ‚úÖ –û—Ç–ª–∏—á–Ω–∞—è  üü° –ß–µ—Ä–µ–∑ –¥–µ—Ç–µ–∫—Ü–∏—é   ‚úÖ –î–ª—è –æ–±—É—á–µ–Ω–∏—è   \n",
      "2        ‚úÖ –û—Ç–ª–∏—á–Ω–∞—è  üü° –ß–µ—Ä–µ–∑ –¥–µ—Ç–µ–∫—Ü–∏—é             ‚úÖ –î–∞   \n",
      "3     üü° –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è         ‚úÖ –•–æ—Ä–æ—à–∞—è            ‚ùå –ù–µ—Ç   \n",
      "\n",
      "            –ì–∏–±–∫–æ—Å—Ç—å –∫–ª–∞—Å—Å–æ–≤  \n",
      "0  ‚úÖ –õ—é–±—ã–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã  \n",
      "1        ‚úÖ –¢–µ–∫—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã  \n",
      "2     ‚ùå –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–ª–∞—Å—Å—ã  \n",
      "3             üü° –û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–∞—è  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "comparison_data = {\n",
    "    '–ú–æ–¥–µ–ª—å': ['CLIP', 'YOLO-World', 'YOLO-E', 'DINO'],\n",
    "    '–û—Å–Ω–æ–≤–Ω–∞—è –∑–∞–¥–∞—á–∞': [\n",
    "        '–°–≤—è–∑—å —Ç–µ–∫—Å—Ç-–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ', \n",
    "        '–î–µ—Ç–µ–∫—Ü–∏—è –ø–æ —Ç–µ–∫—Å—Ç–æ–≤—ã–º –∑–∞–ø—Ä–æ—Å–∞–º',\n",
    "        '–¢—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω–∞—è –¥–µ—Ç–µ–∫—Ü–∏—è –æ–±—ä–µ–∫—Ç–æ–≤',\n",
    "        '–í–∏–∑—É–∞–ª—å–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –±–µ–∑ –º–µ—Ç–æ–∫'\n",
    "    ],\n",
    "    '–¢–∏–ø –æ–±—É—á–µ–Ω–∏—è': [\n",
    "        '–ö–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–æ–µ (—Ç–µ–∫—Å—Ç-–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ)',\n",
    "        'Supervised + —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è', \n",
    "        'Supervised —Å —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –∫–ª–∞—Å—Å–∞–º–∏',\n",
    "        'Self-supervised (–±–µ–∑ –º–µ—Ç–æ–∫)'\n",
    "    ],\n",
    "    'Zero-shot –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏': ['‚úÖ –û—Ç–ª–∏—á–Ω—ã–µ', '‚úÖ –•–æ—Ä–æ—à–∏–µ', '‚ùå –û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–µ', '‚úÖ –•–æ—Ä–æ—à–∏–µ'],\n",
    "    '–î–µ—Ç–µ–∫—Ü–∏—è –æ–±—ä–µ–∫—Ç–æ–≤': ['‚ùå –ù–µ—Ç', '‚úÖ –û—Ç–ª–∏—á–Ω–∞—è', '‚úÖ –û—Ç–ª–∏—á–Ω–∞—è', 'üü° –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è'],\n",
    "    '–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è': ['‚úÖ –û—Ç–ª–∏—á–Ω–∞—è', 'üü° –ß–µ—Ä–µ–∑ –¥–µ—Ç–µ–∫—Ü–∏—é', 'üü° –ß–µ—Ä–µ–∑ –¥–µ—Ç–µ–∫—Ü–∏—é', '‚úÖ –•–æ—Ä–æ—à–∞—è'],\n",
    "    '–¢—Ä–µ–±—É–µ—Ç —Ä–∞–∑–º–µ—Ç–∫–∏': ['‚ùå –ù–µ—Ç', '‚úÖ –î–ª—è –æ–±—É—á–µ–Ω–∏—è', '‚úÖ –î–∞', '‚ùå –ù–µ—Ç'],\n",
    "    '–ì–∏–±–∫–æ—Å—Ç—å –∫–ª–∞—Å—Å–æ–≤': ['‚úÖ –õ—é–±—ã–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã', '‚úÖ –¢–µ–∫—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã', '‚ùå –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–ª–∞—Å—Å—ã', 'üü° –û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–∞—è']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(comparison_data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed13637-9d9c-4e0d-a50e-5aeaf36d5247",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensflow",
   "language": "python",
   "name": "tensflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
